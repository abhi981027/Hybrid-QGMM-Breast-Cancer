# -*- coding: utf-8 -*-
"""breast_cancer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11xmo-qm-E_0Ef9g-mMp7PW7M20KPHpDo
"""

try:
    import cirq
    import cirq_google
except ImportError:
    print("installing cirq...")
    !pip install --quiet cirq-google~=1.0.dev
    print("installed cirq.")
    import cirq
    import cirq_google

# The Google Cloud Project id to use.
project_id = ''
processor_id = ""

from cirq_google.engine.qcs_notebook import get_qcs_objects_for_notebook
# For real engine instances, delete 'virtual=True' below.
qcs_objects = get_qcs_objects_for_notebook(project_id, processor_id, virtual=True)
engine = qcs_objects.engine
processor_id = qcs_objects.processor_id

from google.auth.exceptions import DefaultCredentialsError
from google.api_core.exceptions import PermissionDenied

# Create an Engine object to use, providing the project id and the args
try:
    if qcs_objects.signed_in: # This line only needed for colab testing.
        engine = cirq_google.get_engine()
    print(f"Successful authentication using project {project_id}!")
    print('Available Processors: ')
    print(engine.list_processors())
    print(f'Using processor: {processor_id}')
    processor = engine.get_processor(processor_id)
except DefaultCredentialsError as err:
    print("Could not authenticate to Google Quantum Computing Service.")
    print(" Tips: If you are using Colab: make sure the previous cell was executed successfully.")
    print("       If this notebook is not in Colab (e.g. Jupyter notebook), make sure gcloud is installed and `gcloud auth application-default login` was executed.")
    print()
    print("Error message:")
    print(err)
except PermissionDenied as err:
    print(f"While you are authenticated to Google Cloud it seems the project '{project_id}' does not exist or does not have the Quantum Engine API enabled.")
    print("Error message:")
    print(err)

# A simple example.
q = cirq.GridQubit(5, 2)
circuit = cirq.Circuit(cirq.X(q)**0.5, cirq.measure(q, key='m'))

job = processor.run_sweep(
    program=circuit,
    repetitions=1000)

results = [str(int(b)) for b in job.results()[0].measurements['m'][:, 0]]
print('Success!  Results:')
print(''.join(results))

pip install numpy cirq xgboost scikit-learn tensorflow matplotlib pandas

# Import necessary libraries
import numpy as np
import cirq
import xgboost as xgb
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
import tensorflow as tf
import matplotlib.pyplot as plt
import pandas as pd

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Load the Breast Cancer dataset
data = load_breast_cancer()
X = data.data
y = data.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

print("Training data shape:", X_train.shape)
print("Testing data shape:", X_test.shape)

# Quantum feature transformation function
def quantum_feature_transform(X):
    qubits = [cirq.GridQubit(0, i) for i in range(3)]
    transformed = []

    for x in X:
        circuit = cirq.Circuit()
        for i, feature in enumerate(x[:3]):
            angle = np.pi * feature
            circuit.append(cirq.rx(angle)(qubits[i]))

        for i in range(len(qubits) - 1):
            circuit.append(cirq.CNOT(qubits[i], qubits[i + 1]))

        for i, feature in enumerate(x[:3]):
            param_angle = np.pi / 2 * feature
            circuit.append(cirq.ry(param_angle)(qubits[i]))

        simulator = cirq.Simulator()
        result = simulator.simulate(circuit)
        state_vector = np.real(result.final_state_vector)
        transformed.append(state_vector)

    return np.array(transformed)

# Generate quantum-transformed features
X_train_quantum = quantum_feature_transform(X_train)
X_test_quantum = quantum_feature_transform(X_test)

# QGMM Feature Extraction
def train_qgmm(X):
    gaussians = 3
    dimensionality = X.shape[1]

    # Initialize random means, covariances, and weights
    means = np.random.rand(gaussians, dimensionality)
    covs = np.array([np.eye(dimensionality) for _ in range(gaussians)])
    alphas = np.ones(gaussians) / gaussians

    # Tensor conversion
    obs = tf.convert_to_tensor(X, dtype=tf.float32)
    means = tf.Variable(means, dtype=tf.float32, trainable=True, name="means")
    covs = tf.Variable(covs, dtype=tf.float32, trainable=True, name="covs")
    alphas = tf.Variable(alphas, dtype=tf.float32, trainable=True, name="alphas")

    optimizer = tf.optimizers.Adam(learning_rate=0.01)

    @tf.function
    def qgmm_loss():
        log_likelihood = 0
        for i in range(gaussians):
            cov_inv = tf.linalg.inv(covs[i] + tf.eye(dimensionality) * 1e-6)
            diff = obs - means[i]
            exponent = -0.5 * tf.reduce_sum(diff @ cov_inv * diff, axis=1)
            coef = 1 / tf.sqrt((2 * np.pi) ** dimensionality * tf.linalg.det(covs[i] + tf.eye(dimensionality) * 1e-6))
            gauss_prob = coef * tf.exp(exponent)
            log_likelihood += alphas[i] * gauss_prob
        return -tf.reduce_mean(tf.math.log(log_likelihood + 1e-6))

    for _ in range(50):
        with tf.GradientTape() as tape:
            loss = qgmm_loss()
        gradients = tape.gradient(loss, [means, covs, alphas])
        optimizer.apply_gradients(zip(gradients, [means, covs, alphas]))

    return np.hstack([means.numpy().flatten(), covs.numpy().flatten(), alphas.numpy().flatten()])

# Generate QGMM-based features
qgmm_features_train = np.array([train_qgmm(X_train)])
qgmm_features_test = np.array([train_qgmm(X_test)])

# Replicate the QGMM features for each training and testing sample
qgmm_features_train = np.repeat(qgmm_features_train, len(X_train), axis=0)
qgmm_features_test = np.repeat(qgmm_features_test, len(X_test), axis=0)

# Combine classical, quantum, and QGMM features
X_train_hybrid = np.hstack((X_train, X_train_quantum, qgmm_features_train))
X_test_hybrid = np.hstack((X_test, X_test_quantum, qgmm_features_test))

print("Hybrid Training Data Shape:", X_train_hybrid.shape)
print("Hybrid Testing Data Shape:", X_test_hybrid.shape)

# Early stopping to avoid overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Hybrid Quantum-Classical Neural Network
model_hybrid = Sequential([
    Dense(512, activation='relu', input_shape=(X_train_hybrid.shape[1],)),
    BatchNormalization(),
    Dropout(0.4),
    Dense(256, activation='relu'),
    Dropout(0.3),
    Dense(128, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])

model_hybrid.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model_hybrid.fit(X_train_hybrid, y_train, validation_split=0.2, epochs=50, batch_size=32, verbose=1, callbacks=[early_stopping])

# Evaluate the hybrid model
y_pred_hybrid = (model_hybrid.predict(X_test_hybrid) > 0.5).astype(int)
hybrid_accuracy = accuracy_score(y_test, y_pred_hybrid)
print(f"\nQuantum-Enhanced Hybrid QGMM Model Accuracy: {hybrid_accuracy:.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_hybrid))

# Accuracy comparison plot
plt.figure(figsize=(8, 5))
plt.bar(['Quantum-Enhanced Hybrid QGMM'], [hybrid_accuracy], color='purple')
plt.title('Accuracy of the Quantum-Enhanced Hybrid QGMM Model')
plt.ylabel('Accuracy')
plt.ylim(0.8, 1.0)
plt.show()

# Import necessary libraries
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import classification_report

# Function to plot the comparison of classification reports
def plot_seating_layout(reports, labels, title):
    num_reports = len(reports)
    fig, axes = plt.subplots(1, num_reports, figsize=(20, 8), constrained_layout=True)

    for i, (report, label) in enumerate(zip(reports, labels)):
        # Convert the report dictionary to a DataFrame for better visualization
        df = pd.DataFrame(report).transpose()
        df = df.round(4)  # Round for better readability

        # Plot the table in the subplot
        axes[i].axis('tight')
        axes[i].axis('off')
        table = axes[i].table(cellText=df.values, colLabels=df.columns, rowLabels=df.index, loc='center', cellLoc='center')

        # Set table properties for better visualization
        table.auto_set_font_size(False)
        table.set_fontsize(12)
        table.scale(1.5, 1.5)
        axes[i].set_title(label, fontsize=18, color='darkblue')

    plt.suptitle(title, fontsize=22, color='purple', y=1.05)
    plt.show()

# Train a classical XGBoost model for comparison
classical_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
classical_model.fit(X_train, y_train)
y_pred_classical = classical_model.predict(X_test)

# Train a quantum-only neural network for comparison
model_quantum = Sequential([
    Dense(128, activation='relu', input_shape=(X_train_quantum.shape[1],)),
    BatchNormalization(),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dropout(0.1),
    Dense(1, activation='sigmoid')
])
model_quantum.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model_quantum.fit(X_train_quantum, y_train, validation_split=0.2, epochs=30, batch_size=32, verbose=1, callbacks=[early_stopping])

# Quantum-only predictions and accuracy
y_pred_quantum = (model_quantum.predict(X_test_quantum) > 0.5).astype(int)

# Generate classification reports as dictionaries
classical_report = classification_report(y_test, y_pred_classical, target_names=['Benign', 'Malignant'], output_dict=True)
quantum_report = classification_report(y_test, y_pred_quantum, target_names=['Benign', 'Malignant'], output_dict=True)
hybrid_report = classification_report(y_test, y_pred_hybrid, target_names=['Benign', 'Malignant'], output_dict=True)

# Plot the seating layout of the reports
plot_seating_layout(
    reports=[classical_report, quantum_report, hybrid_report],
    labels=['Classical Model', 'Quantum Model', 'Hybrid Model'],
    title='Comparison of Classification Reports for Classical, Quantum, and Hybrid Models'
)

# Import necessary libraries
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay

# Function to plot prediction comparison for Classical, Quantum, and Hybrid models
def plot_prediction_comparison(predictions, labels, y_test, title):
    num_models = len(predictions)
    fig, axes = plt.subplots(1, num_models, figsize=(24, 8), constrained_layout=True)

    for i, (y_pred, label) in enumerate(zip(predictions, labels)):
        # Confusion Matrix
        cm = confusion_matrix(y_test, y_pred)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign', 'Malignant'])

        # ROC Curve
        fpr, tpr, _ = roc_curve(y_test, y_pred)
        roc_auc = auc(fpr, tpr)

        # Plot Confusion Matrix
        disp.plot(ax=axes[i], cmap=plt.cm.Purples, values_format='d')
        axes[i].set_title(f"{label} - Confusion Matrix", fontsize=18, color='darkblue')
        axes[i].set_xlabel('Predicted Label')
        axes[i].set_ylabel('True Label')

        # Add ROC Curve to the same plot
        ax2 = axes[i].twinx()  # Twin axis to overlay ROC curve
        ax2.plot(fpr, tpr, color='red', label=f'ROC Curve (AUC = {roc_auc:.4f})', linewidth=2)
        ax2.plot([0, 1], [0, 1], 'k--', label='Random Guess')
        ax2.set_ylabel('True Positive Rate')
        ax2.legend(loc='lower right')

    plt.suptitle(title, fontsize=22, color='purple', y=1.05)
    plt.show()

# Generating predictions from each model
print("Generating predictions for Classical, Quantum, and Hybrid models...")

# Classical Model Predictions (consistent with the first code)
classical_pred = classical_model.predict(X_test)

# Quantum Model Predictions (consistent with the first code)
quantum_pred = (model_quantum.predict(X_test_quantum) > 0.5).astype(int)

# Hybrid Model Predictions (consistent with the first code)
hybrid_pred = (model_hybrid.predict(X_test_hybrid) > 0.5).astype(int)

# Plot the prediction comparison charts
plot_prediction_comparison(
    predictions=[classical_pred, quantum_pred, hybrid_pred],
    labels=['Classical Model', 'Quantum Model', 'Hybrid Model'],
    y_test=y_test,
    title='Comparison of Predictions: Classical, Quantum, and Hybrid Models'
)

# ROC Curve Comparison
plt.figure(figsize=(10, 7))

# Classical Model ROC Curve
y_pred_prob_classical = classical_model.predict_proba(X_test)[:, 1]
fpr_classical, tpr_classical, _ = roc_curve(y_test, y_pred_prob_classical)
roc_auc_classical = auc(fpr_classical, tpr_classical)
plt.plot(fpr_classical, tpr_classical, color='blue', label=f'Classical Model (AUC = {roc_auc_classical:.4f})', linewidth=2)

# Quantum Model ROC Curve
y_pred_prob_quantum = model_quantum.predict(X_test_quantum).ravel()
fpr_quantum, tpr_quantum, _ = roc_curve(y_test, y_pred_prob_quantum)
roc_auc_quantum = auc(fpr_quantum, tpr_quantum)
plt.plot(fpr_quantum, tpr_quantum, color='green', label=f'Quantum Model (AUC = {roc_auc_quantum:.4f})', linewidth=2)

# Hybrid Model ROC Curve
y_pred_prob_hybrid = model_hybrid.predict(X_test_hybrid).ravel()
fpr_hybrid, tpr_hybrid, _ = roc_curve(y_test, y_pred_prob_hybrid)
roc_auc_hybrid = auc(fpr_hybrid, tpr_hybrid)
plt.plot(fpr_hybrid, tpr_hybrid, color='purple', label=f'Hybrid Model (AUC = {roc_auc_hybrid:.4f})', linewidth=2)

# Plotting the ROC Curve
plt.plot([0, 1], [0, 1], 'r--', label='Random Guess', linewidth=1)
plt.title('ROC Curve Comparison of Classical, Quantum, and Hybrid Models', fontsize=22, color='purple', y=1.05)
plt.xlabel('False Positive Rate', fontsize=16)
plt.ylabel('True Positive Rate', fontsize=16)
plt.legend(loc='lower right', fontsize=14)
plt.grid(True, linestyle='--', alpha=0.6)
plt.show()

import cirq
import numpy as np
import matplotlib.pyplot as plt

# Quantum circuit visualization function
def visualize_quantum_circuit(sample_input):
    # Define 3 qubits in a grid
    qubits = [cirq.GridQubit(0, i) for i in range(3)]
    circuit = cirq.Circuit()

    # Apply rotations based on input features
    for i, feature in enumerate(sample_input[:3]):
        angle = np.pi * feature
        circuit.append(cirq.rx(angle)(qubits[i]))

    # Apply entanglement (CNOT gates)
    for i in range(len(qubits) - 1):
        circuit.append(cirq.CNOT(qubits[i], qubits[i + 1]))

    # Apply parameterized rotations for encoding
    for i, feature in enumerate(sample_input[:3]):
        param_angle = np.pi / 2 * feature
        circuit.append(cirq.ry(param_angle)(qubits[i]))

    # Print and visualize the circuit
    print("\nQuantum Circuit for Feature Transformation:")
    print(circuit)

    # Use Cirq's built-in method to plot the circuit
    cirq.plot_state_histogram(cirq.Simulator().simulate(circuit).final_state_vector, plt.subplot(111))
    plt.title("Quantum Circuit State Vector Visualization")
    plt.show()

# Visualize the quantum circuit with a sample input
sample_input = X_train[0]  # Take the first sample from the training data
visualize_quantum_circuit(sample_input)

# XGBoost feature importance
xgb_model = xgb.XGBClassifier()
xgb_model.fit(X_train_hybrid, y_train)

# Plot feature importances
plt.figure(figsize=(12, 8))
xgb.plot_importance(xgb_model, max_num_features=20, importance_type='weight', height=0.5, color='purple')
plt.title('Feature Importance (XGBoost)')
plt.show()
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_hybrid)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Purples', cbar=False)
plt.title('Confusion Matrix of Quantum-Enhanced Hybrid QGMM Model')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Import necessary libraries for plotting and visualization
from sklearn.manifold import TSNE
from sklearn.metrics import precision_recall_curve, f1_score
import seaborn as sns
from cirq import bloch_vector_from_state_vector
from mpl_toolkits.mplot3d import Axes3D

# t-SNE Plot for Hybrid Features
tsne = TSNE(n_components=2, random_state=42)
X_train_tsne = tsne.fit_transform(X_train_hybrid)

plt.figure(figsize=(8, 6))
plt.scatter(X_train_tsne[y_train == 0, 0], X_train_tsne[y_train == 0, 1],
            color='blue', alpha=0.6, label='Class 0', marker='o')
plt.scatter(X_train_tsne[y_train == 1, 0], X_train_tsne[y_train == 1, 1],
            color='red', alpha=0.6, label='Class 1', marker='^')
plt.title('t-SNE Visualization of Hybrid Features')
plt.xlabel('t-SNE Component 1')
plt.ylabel('t-SNE Component 2')
plt.legend()
plt.grid(True)
plt.show()

# Precision-Recall Curve with Improved Annotations
y_pred_proba = model_hybrid.predict(X_test_hybrid)
precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)

plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='purple', linewidth=2, label='Precision-Recall Curve')
plt.title('Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.legend(loc='lower left')
plt.grid(True)
plt.annotate(f'AP: {np.mean(precision):.2f}', xy=(0.6, 0.6), fontsize=12)
plt.show()

# Compare with a simple XGBoost model
xgb_model = xgb.XGBClassifier()
xgb_model.fit(X_train, y_train)
xgb_pred = xgb_model.predict(X_test)
xgb_accuracy = accuracy_score(y_test, xgb_pred)
xgb_f1 = f1_score(y_test, xgb_pred)

# Enhanced Model Comparison Bar Plot
plt.figure(figsize=(8, 6))
models = ['Hybrid QGMM', 'Classical XGBoost']
accuracies = [hybrid_accuracy, xgb_accuracy]
f1_scores = [f1_score(y_test, y_pred_hybrid), xgb_f1]

# Plotting accuracy and F1-score side by side
x = range(len(models))
width = 0.4
plt.bar(x, accuracies, width=width, label='Accuracy', color='purple', align='center')
plt.bar([p + width for p in x], f1_scores, width=width, label='F1-Score', color='orange', align='center')

plt.title('Model Accuracy and F1-Score Comparison')
plt.xlabel('Model Type')
plt.ylabel('Performance Metrics')
plt.ylim(0.8, 1.0)
plt.xticks([p + width / 2 for p in x], models)
plt.legend()
plt.show()

# Density Plot of Predicted Probabilities
plt.figure(figsize=(8, 6))
sns.kdeplot(y_pred_proba[y_test == 0], label='Class 0', shade=True, color='blue')
sns.kdeplot(y_pred_proba[y_test == 1], label='Class 1', shade=True, color='red')
plt.title('Density Plot of Predicted Probabilities')
plt.xlabel('Predicted Probability')
plt.ylabel('Density')
plt.legend()
plt.grid(True)
plt.show()

# Quantum State Visualization with Bloch Sphere
circuit = cirq.Circuit()
qubits = [cirq.GridQubit(0, i) for i in range(3)]
x = X_train[0][:3]

for i, feature in enumerate(x):
    angle = np.pi * feature
    circuit.append(cirq.rx(angle)(qubits[i]))

for i in range(len(qubits) - 1):
    circuit.append(cirq.CNOT(qubits[i], qubits[i + 1]))

for i, feature in enumerate(x):
    param_angle = np.pi / 2 * feature
    circuit.append(cirq.ry(param_angle)(qubits[i]))

simulator = cirq.Simulator()
result = simulator.simulate(circuit)
bloch_vector = bloch_vector_from_state_vector(result.final_state_vector, 0)

fig = plt.figure(figsize=(8, 8))
ax = fig.add_subplot(111, projection='3d')
ax.quiver(0, 0, 0, bloch_vector[0], bloch_vector[1], bloch_vector[2], color='purple', linewidth=3)
ax.set_xlim([-1, 1])
ax.set_ylim([-1, 1])
ax.set_zlim([-1, 1])
ax.set_title('Bloch Sphere Visualization of Quantum State')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()